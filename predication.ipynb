import datetime
import pandas_datareader.data as web
import math
import numpy as np
import matplotlib.pyplot as plt
from pandas import Series, DataFrame

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor


def plotgraph(dataset,forecast):
  last_date = dataset.iloc[-1].name
  last_unix = last_date
  next_unix = last_unix + datetime.timedelta(days=1)
  
  for i in forecast:
    next_date = next_unix
    next_unix += datetime.timedelta(days=1)
    dfreg.loc[next_date] = [np.nan for _ in range(len(dataset.columns)-1)]+[i]

  dataset['Adj Close'].tail(500).plot()
  dataset['Forecast'].tail(500).plot()
  plt.legend(loc=4)
  plt.xlabel('Date')
  plt.ylabel('Price')
  plt.show()

start = datetime.datetime(2010, 1, 1)
end = datetime.datetime(2017, 1, 11)

df = web.DataReader("AAPL", 'yahoo', start, end)

dfreg = df.loc[:,['Adj Close','Volume']]
dfreg['HL_PCT'] = (df['High'] - df['Low']) / df['Close'] * 100.0
dfreg['PCT_change'] = (df['Close'] - df['Open']) / df['Open'] * 100.0

# Drop missing value
dfreg.fillna(value=-99999, inplace=True)
# We want to separate 1 percent of the data to forecast
forecast_out = int(math.ceil(0.01 * len(dfreg)))
# Separating the label here, we want to predict the AdjClose
forecast_col = 'Adj Close'
dfreg['label'] = dfreg[forecast_col].shift(-forecast_out)
X = np.array(dfreg.drop(['label'], 1))
# Scale the X so that everyone can have the same distribution for linear regression
X = preprocessing.scale(X)
# Finally We want to find Data Series of late X and early X (train) for model generation and evaluation
X_lately = X[-forecast_out:]
X = X[:-forecast_out]
# Separate label and identify it as y
y = np.array(dfreg['label'])
y = y[:-forecast_out]

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size= 0.3)

# Linear regression
clfreg = LinearRegression(n_jobs=-1)
clfreg.fit(X_train, y_train)

# # KNN Regression
clfknn = KNeighborsRegressor(n_neighbors=2)
clfknn.fit(X_train, y_train)

#DecisionTree Regressor
clftree = DecisionTreeRegressor(max_depth=300)
clftree.fit(X_train, y_train)

#Decision Tree Regression with ada boost
rng = np.random.RandomState(1)
clftreeada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),
                          n_estimators=300, random_state=rng)
clftreeada.fit(X_train, y_train)

forecast_reg = clfreg.predict(X_lately)
forecast_knn = clfknn.predict(X_lately)
forecast_tree = clftree.predict(X_lately)
forecast_treeada = clftreeada.predict(X_lately)
dfreg['Forecast'] = np.nan

plotgraph(dfreg,forecast_reg)
plotgraph(dfreg,forecast_knn)
plotgraph(dfreg,forecast_tree)
plotgraph(dfreg,forecast_treeada)
